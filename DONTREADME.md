# pun

## Goals

### Identifiability

> Does `pun` limit the vocabulary it uses?

Yep. This keeps the tool from creating puns with weird obscure words terms that would fly over most people's heads.

> Does the vocabulary rely on a dictionary?

Yes. `pun` draws its vocabulary from English Wiktionary entries.

> Does the vocabulary rely on Wikipedia?

Nope. Wikipedia terms minus English Wiktionary English terms would mostly just end up with specialized named entities.

> Does `pun` filter vocabulary by word frequency?

Nah. Word frequency alone doesn't determine how identifiable a term is. For example, "ungoogleable" barely registers on frequency lists, but everyone knows what it means because it's derived from "Google".

Plus, frequency filtering gets messy with phrases, which can show up in all sorts of variations and are a pain to count.

Instead, `pun` uses large language models to score how recognizable each word is, then filters based on those scores.

> Does `pun` use local LLMs for recognizability scoring?

Nah. Remote LLMs give state-of-the-art results.

> Does `pun` calculate recognizability scores on the fly?

No. The scores are precomputed because:

- API calls to remote LLMs cost actual cash.

- Running scoring takes time.

- Random API failures would break your pun flow.

> Are the precomputed scores committed to this repository?

Nah. These scores are generated data, not source code.

> Are the precomputed scores included in automated releases?

No way. The scoring process occasionally needs manual babysitting. API calls might fail, models might return garbage, or other random stuff can go wrong. Since it costs real money to run these LLM calls, I don't want to blindly retry in an automated pipeline. It's the kind of process I want to run manually, check the results, and then commit when I'm satisfied.

### Relevance

> What metric is used to evaluate the relevance of puns generated by `pun`?

`pun` uses cosine similarity to check how relevant the puns are.

### Quantity

> Does `pun` aim to generate more than one pun?

Yep! The tool tries to give you multiple puns for your content. This is super helpful when you're jumping into comment threads. You'll have different puns ready for different replies without recycling the same one.

### Latency

> What's the target response time for `pun`?

The target response time is one second flat. "[1.0 second is about the limit for the user's flow of thought to stay uninterrupted](https://www.nngroup.com/articles/response-times-3-important-limits/#:~:text=1.0%20second%20is%20about%20the%20limit%20for%20the%20user's%20flow%20of%20thought%20to%20stay%20uninterrupted)".

## Substitution

> Can `pun` use homophones for substitution?

Yep! `pun` can totally use homophones for substitution. But it's not limited to perfect homophones. The tool works with words that share significant phonetic similarity too, which gives it way more flexibility when cranking out puns.

> What metric is used to calculate phonetic similarity?

`pun` uses Levenshtein distance on International Phonetic Alphabet (IPA) representations. For substitution jokes to land, the audience has to recognize the original phrase being referenced. The tool converts words to their IPA representation and then calculates the Levenshtein distance between them to figure out how phonetically similar they are. This approach makes sure substitutions keep enough phonetic similarity to keep the puns identifiable.

> What library does `pun` use for converting English text to IPA?

`pun` uses [`epitran`](https://github.com/dmort27/epitran). I tried [`eng_to_ipa`](https://github.com/mphilli/English-to-IPA), [`espeak-ng`](https://github.com/espeak-ng/espeak-ng), and [`g2p`](https://github.com/roedoejet/g2p) too, but they weren't accurate enough.

> Does `pun` use dictionaries for converting English text to IPA?

Nope. Using dictionaries alone runs into these problems:

- Dictionaries might miss words that are well-known but not super common, like "ungoogleable".

- Dictionary lookups struggle with how words change pronunciation in context, like how "the" sounds different before vowels versus consonants.

Sure, I could try to bolt dictionaries onto a conversion library for better accuracy, but that's a job for the IPA conversion library itself, not `pun`.

> Are the results sorted by Levenshtein distance?

Nope! Here's why:

- Phonetic similarity is just one piece of what makes a pun work

- Creating a weighting between different factors would be arbitrary

- Showing puns as they're generated means you see results immediately

> Can `pun` generate ungrammatical puns?

Yep. That's because:

- Plenty of good puns break grammar rules on purpose.

- You can tweak the grammar yourself after getting the core wordplay idea, often needing to change more than just the substituted word to make it flow.

> Can `pun` generate multiple puns that differ only in the grammatical form of the substituted word?

Yep! These aren't filtered out because:

- Different forms might land better depending on where you're using the pun.

- Forcing you to mentally transform words wastes your brain power.
